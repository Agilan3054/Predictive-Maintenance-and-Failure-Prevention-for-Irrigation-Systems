{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Vrub6btjU6K",
        "outputId": "b970898f-9ea9-47a4-90c0-bba9fcb2b2b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            timestamp  soil_moisture  temperature  rainfall   humidity  \\\n",
            "0 2024-01-01 00:00:00      54.967142    31.996777  3.649643  41.382887   \n",
            "1 2024-01-01 01:00:00      48.617357    29.623168  4.710963  57.094225   \n",
            "2 2024-01-01 02:00:00      56.476885    25.298152  3.415160  63.795917   \n",
            "3 2024-01-01 03:00:00      65.230299    21.765316  4.384077  98.315315   \n",
            "4 2024-01-01 04:00:00      47.658466    28.491117  1.212771  78.348297   \n",
            "\n",
            "   water_flow  pressure  failure_event  \n",
            "0   82.730128  2.788120              0  \n",
            "1   99.375930  2.773293              0  \n",
            "2  100.360337  2.102178              0  \n",
            "3  109.452607  2.834955              0  \n",
            "4   72.662833  3.366415              1  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-ecde4f803189>:11: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  time_steps = pd.date_range(start=\"2024-01-01\", periods=n_records, freq='H')\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Define simulation parameters\n",
        "n_records = 1000\n",
        "time_steps = pd.date_range(start=\"2024-01-01\", periods=n_records, freq='H')\n",
        "\n",
        "# Simulate sensor data for soil moisture, temperature, pressure, water flow, and rainfall\n",
        "soil_moisture = np.random.normal(loc=50, scale=10, size=n_records)  # Soil moisture level in percentage\n",
        "temperature = np.random.normal(loc=25, scale=5, size=n_records)  # Temperature in °C\n",
        "rainfall = np.random.normal(loc=5, scale=2, size=n_records)  # Rainfall in mm\n",
        "humidity = np.random.normal(loc=70, scale=15, size=n_records)  # Humidity in percentage\n",
        "water_flow = np.random.normal(loc=100, scale=20, size=n_records)  # Water flow rate in liters/hour\n",
        "pressure = np.random.normal(loc=3, scale=0.5, size=n_records)  # Pressure in bar\n",
        "\n",
        "# Failure events: 1 means failure occurs at that time step, 0 means no failure\n",
        "failure_event = np.random.choice([0, 1], size=n_records, p=[0.9, 0.1])  # 10% failure rate\n",
        "\n",
        "# Create the dataframe\n",
        "data = pd.DataFrame({\n",
        "    'timestamp': time_steps,\n",
        "    'soil_moisture': soil_moisture,\n",
        "    'temperature': temperature,\n",
        "    'rainfall': rainfall,\n",
        "    'humidity': humidity,\n",
        "    'water_flow': water_flow,\n",
        "    'pressure': pressure,\n",
        "    'failure_event': failure_event\n",
        "})\n",
        "\n",
        "# Save data to CSV\n",
        "data.to_csv('enhanced_irrigation_data.csv', index=False)\n",
        "\n",
        "# Display the first few records\n",
        "print(data.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the enhanced dataset\n",
        "data = pd.read_csv('enhanced_irrigation_data.csv')\n",
        "\n",
        "# Handle missing values (if any)\n",
        "data = data.fillna(method='ffill')\n",
        "\n",
        "# Feature engineering\n",
        "data['temp_diff'] = data['temperature'].diff().fillna(0)  # Temperature difference from the previous step\n",
        "data['soil_moisture_trend'] = data['soil_moisture'].rolling(window=5).mean().fillna(data['soil_moisture'])  # 5-hour rolling average of soil moisture\n",
        "\n",
        "# Features and target variable\n",
        "X = data[['soil_moisture', 'temperature', 'rainfall', 'humidity', 'water_flow', 'pressure', 'temp_diff', 'soil_moisture_trend']]\n",
        "y = data['failure_event']\n",
        "\n",
        "# Normalize the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Training set size: {X_train.shape}\")\n",
        "print(f\"Test set size: {X_test.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DdQC2YjkjX8S",
        "outputId": "60e8a6a5-701e-4111-e95d-a36d69c3d4bf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: (800, 8)\n",
            "Test set size: (200, 8)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-4c5cc5d072e1>:8: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  data = data.fillna(method='ffill')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Initialize models\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "gb_model = GradientBoostingClassifier(random_state=42)\n",
        "xgb_model = XGBClassifier(random_state=42)\n",
        "\n",
        "# Corrected param_grid for RandomForestClassifier\n",
        "param_grid_rf = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_features': ['auto', 'sqrt', 'log2'],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'bootstrap': [True, False]\n",
        "}\n",
        "\n",
        "# GridSearchCV for RandomForestClassifier\n",
        "grid_rf = GridSearchCV(estimator=rf_model, param_grid=param_grid_rf, cv=5, n_jobs=-1)\n",
        "grid_rf.fit(X_train, y_train)\n",
        "\n",
        "# GridSearchCV for GradientBoosting\n",
        "grid_gb = GridSearchCV(estimator=gb_model, param_grid=param_grid, cv=5, n_jobs=-1)\n",
        "grid_gb.fit(X_train, y_train)\n",
        "\n",
        "# GridSearchCV for XGBoost\n",
        "grid_xgb = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=5, n_jobs=-1)\n",
        "grid_xgb.fit(X_train, y_train)\n",
        "\n",
        "# Display best parameters\n",
        "print(\"Best parameters for RandomForest:\", grid_rf.best_params_)\n",
        "print(\"Best parameters for GradientBoosting:\", grid_gb.best_params_)\n",
        "print(\"Best parameters for XGBoost:\", grid_xgb.best_params_)\n",
        "\n",
        "# Evaluate models\n",
        "y_pred_rf = grid_rf.predict(X_test)\n",
        "y_pred_gb = grid_gb.predict(X_test)\n",
        "y_pred_xgb = grid_xgb.predict(X_test)\n",
        "\n",
        "print(\"RandomForest Classifier Evaluation:\\n\", classification_report(y_test, y_pred_rf))\n",
        "print(\"GradientBoosting Classifier Evaluation:\\n\", classification_report(y_test, y_pred_gb))\n",
        "print(\"XGBoost Classifier Evaluation:\\n\", classification_report(y_test, y_pred_xgb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "b63Maq7WjbD9",
        "outputId": "257cc775-3e9d-4442-9069-77a911580796"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
            "1080 fits failed out of a total of 3240.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "417 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1466, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 666, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "663 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1466, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 666, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/ma/core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
            "  _data = np.array(data, dtype=dtype, copy=copy,\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the test scores are non-finite: [    nan     nan     nan     nan     nan     nan     nan     nan     nan\n",
            "     nan     nan     nan     nan     nan     nan     nan     nan     nan\n",
            "     nan     nan     nan     nan     nan     nan     nan     nan     nan\n",
            " 0.9075  0.90875 0.90875 0.905   0.90625 0.905   0.9025  0.905   0.905\n",
            " 0.91    0.91    0.91    0.91    0.91    0.91125 0.91125 0.91125 0.91125\n",
            " 0.91125 0.91125 0.91125 0.91125 0.91125 0.91125 0.91125 0.91125 0.91125\n",
            " 0.90375 0.90375 0.90375 0.90375 0.90375 0.905   0.90375 0.905   0.905\n",
            " 0.91    0.91    0.91    0.91    0.91    0.91    0.91125 0.91125 0.91125\n",
            " 0.91125 0.91125 0.91125 0.91125 0.91125 0.91125 0.91125 0.91125 0.91125\n",
            "     nan     nan     nan     nan     nan     nan     nan     nan     nan\n",
            "     nan     nan     nan     nan     nan     nan     nan     nan     nan\n",
            "     nan     nan     nan     nan     nan     nan     nan     nan     nan\n",
            " 0.90875 0.90875 0.91    0.905   0.90625 0.90625 0.90625 0.9075  0.9075\n",
            " 0.91    0.91125 0.91125 0.91    0.91125 0.91125 0.91125 0.91125 0.91125\n",
            " 0.91125 0.91125 0.91125 0.91125 0.91125 0.91125 0.91125 0.91125 0.91125\n",
            " 0.90125 0.905   0.905   0.905   0.905   0.905   0.90625 0.905   0.905\n",
            " 0.91125 0.91    0.91    0.91    0.91    0.91    0.91125 0.91125 0.91125\n",
            " 0.91125 0.91125 0.91125 0.91125 0.91125 0.91125 0.91125 0.91125 0.91125\n",
            "     nan     nan     nan     nan     nan     nan     nan     nan     nan\n",
            "     nan     nan     nan     nan     nan     nan     nan     nan     nan\n",
            "     nan     nan     nan     nan     nan     nan     nan     nan     nan\n",
            " 0.9075  0.90875 0.90875 0.905   0.90625 0.905   0.9025  0.905   0.905\n",
            " 0.91    0.91    0.91    0.91    0.91    0.91125 0.91125 0.91125 0.91125\n",
            " 0.91125 0.91125 0.91125 0.91125 0.91125 0.91125 0.91125 0.91125 0.91125\n",
            " 0.90125 0.90375 0.905   0.90375 0.90375 0.905   0.90375 0.905   0.905\n",
            " 0.91    0.91    0.91    0.91    0.91    0.91    0.91125 0.91125 0.91125\n",
            " 0.91125 0.91125 0.91125 0.91125 0.91125 0.91125 0.91125 0.91125 0.91125\n",
            "     nan     nan     nan     nan     nan     nan     nan     nan     nan\n",
            "     nan     nan     nan     nan     nan     nan     nan     nan     nan\n",
            "     nan     nan     nan     nan     nan     nan     nan     nan     nan\n",
            " 0.9075  0.90875 0.90875 0.905   0.90625 0.905   0.9025  0.905   0.905\n",
            " 0.91    0.91    0.91    0.91    0.91    0.91125 0.91125 0.91125 0.91125\n",
            " 0.91125 0.91125 0.91125 0.91125 0.91125 0.91125 0.91125 0.91125 0.91125\n",
            " 0.90375 0.90375 0.90375 0.90375 0.90375 0.905   0.90375 0.905   0.905\n",
            " 0.91    0.91    0.91    0.91    0.91    0.91    0.91125 0.91125 0.91125\n",
            " 0.91125 0.91125 0.91125 0.91125 0.91125 0.91125 0.91125 0.91125 0.91125\n",
            "     nan     nan     nan     nan     nan     nan     nan     nan     nan\n",
            "     nan     nan     nan     nan     nan     nan     nan     nan     nan\n",
            "     nan     nan     nan     nan     nan     nan     nan     nan     nan\n",
            " 0.89875 0.89875 0.89875 0.89875 0.89875 0.89875 0.9025  0.90375 0.90375\n",
            " 0.90625 0.90875 0.90625 0.90875 0.90875 0.9075  0.91125 0.91125 0.91\n",
            " 0.91    0.91    0.91    0.91    0.91    0.91    0.91125 0.91125 0.91\n",
            " 0.89875 0.8975  0.8975  0.89875 0.89875 0.89875 0.9025  0.9025  0.9025\n",
            " 0.905   0.905   0.90625 0.90625 0.90625 0.90625 0.91    0.91    0.91\n",
            " 0.91    0.91    0.91    0.91    0.91    0.91    0.91    0.91    0.91\n",
            "     nan     nan     nan     nan     nan     nan     nan     nan     nan\n",
            "     nan     nan     nan     nan     nan     nan     nan     nan     nan\n",
            "     nan     nan     nan     nan     nan     nan     nan     nan     nan\n",
            " 0.89875 0.9     0.9     0.89875 0.9     0.9     0.90375 0.90375 0.90375\n",
            " 0.9075  0.9075  0.9075  0.90625 0.9075  0.90625 0.91125 0.91125 0.91\n",
            " 0.91125 0.91125 0.91    0.91125 0.91125 0.91    0.91125 0.91125 0.91125\n",
            " 0.89875 0.89875 0.89875 0.89875 0.89875 0.89875 0.90375 0.90375 0.90375\n",
            " 0.90625 0.90625 0.90625 0.90625 0.90625 0.90625 0.91    0.91    0.91\n",
            " 0.91    0.91    0.91    0.91    0.91    0.91    0.91    0.91    0.91\n",
            "     nan     nan     nan     nan     nan     nan     nan     nan     nan\n",
            "     nan     nan     nan     nan     nan     nan     nan     nan     nan\n",
            "     nan     nan     nan     nan     nan     nan     nan     nan     nan\n",
            " 0.89875 0.89875 0.89875 0.89875 0.89875 0.89875 0.9025  0.90375 0.90375\n",
            " 0.90625 0.9075  0.9075  0.90875 0.90875 0.9075  0.91125 0.91125 0.91\n",
            " 0.91    0.91    0.91    0.91    0.91    0.91    0.91125 0.91125 0.91\n",
            " 0.8975  0.8975  0.8975  0.89875 0.89875 0.89875 0.90375 0.90375 0.90375\n",
            " 0.905   0.905   0.90625 0.90625 0.90625 0.90625 0.91    0.91    0.91\n",
            " 0.91    0.91    0.91    0.91    0.91    0.91    0.91    0.91    0.91\n",
            "     nan     nan     nan     nan     nan     nan     nan     nan     nan\n",
            "     nan     nan     nan     nan     nan     nan     nan     nan     nan\n",
            "     nan     nan     nan     nan     nan     nan     nan     nan     nan\n",
            " 0.89875 0.89875 0.89875 0.89875 0.89875 0.89875 0.9025  0.90375 0.90375\n",
            " 0.90625 0.90875 0.90625 0.90875 0.90875 0.9075  0.91125 0.91125 0.91\n",
            " 0.91    0.91    0.91    0.91    0.91    0.91    0.91125 0.91125 0.91\n",
            " 0.89875 0.8975  0.8975  0.89875 0.89875 0.89875 0.9025  0.9025  0.9025\n",
            " 0.905   0.905   0.90625 0.90625 0.90625 0.90625 0.91    0.91    0.91\n",
            " 0.91    0.91    0.91    0.91    0.91    0.91    0.91    0.91    0.91   ]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters for RandomForest: {'bootstrap': True, 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 300}\n",
            "Best parameters for GradientBoosting: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 50, 'subsample': 0.8}\n",
            "Best parameters for XGBoost: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 50, 'subsample': 0.8}\n",
            "RandomForest Classifier Evaluation:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      1.00      0.95       182\n",
            "           1       0.00      0.00      0.00        18\n",
            "\n",
            "    accuracy                           0.91       200\n",
            "   macro avg       0.46      0.50      0.48       200\n",
            "weighted avg       0.83      0.91      0.87       200\n",
            "\n",
            "GradientBoosting Classifier Evaluation:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      1.00      0.95       182\n",
            "           1       0.00      0.00      0.00        18\n",
            "\n",
            "    accuracy                           0.91       200\n",
            "   macro avg       0.46      0.50      0.48       200\n",
            "weighted avg       0.83      0.91      0.87       200\n",
            "\n",
            "XGBoost Classifier Evaluation:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      1.00      0.95       182\n",
            "           1       0.00      0.00      0.00        18\n",
            "\n",
            "    accuracy                           0.91       200\n",
            "   macro avg       0.46      0.50      0.48       200\n",
            "weighted avg       0.83      0.91      0.87       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Scale the data for Autoencoder\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled_autoencoder = scaler.fit_transform(X)\n",
        "\n",
        "# Build Autoencoder model\n",
        "autoencoder = Sequential()\n",
        "autoencoder.add(Dense(64, activation='relu', input_dim=X_scaled_autoencoder.shape[1]))\n",
        "autoencoder.add(Dropout(0.2))\n",
        "autoencoder.add(Dense(32, activation='relu'))\n",
        "autoencoder.add(Dropout(0.2))\n",
        "autoencoder.add(Dense(16, activation='relu'))\n",
        "autoencoder.add(Dense(X_scaled_autoencoder.shape[1], activation='sigmoid'))  # Output layer with same dimension as input\n",
        "\n",
        "autoencoder.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Train the Autoencoder model\n",
        "autoencoder.fit(X_scaled_autoencoder, X_scaled_autoencoder, epochs=20, batch_size=64)\n",
        "\n",
        "# Use the trained Autoencoder to detect anomalies (i.e., high reconstruction error)\n",
        "reconstruction_error = autoencoder.evaluate(X_scaled_autoencoder, X_scaled_autoencoder)\n",
        "\n",
        "print(f\"Reconstruction error: {reconstruction_error}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqT24X5NjfYH",
        "outputId": "0c4b2f6d-1823-4d94-9dea-fee314dc67c0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0262\n",
            "Epoch 2/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0246\n",
            "Epoch 3/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0247\n",
            "Epoch 4/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0235\n",
            "Epoch 5/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0217\n",
            "Epoch 6/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0206\n",
            "Epoch 7/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0203\n",
            "Epoch 8/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0193\n",
            "Epoch 9/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0180\n",
            "Epoch 10/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0168 \n",
            "Epoch 11/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0156 \n",
            "Epoch 12/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0142 \n",
            "Epoch 13/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0136 \n",
            "Epoch 14/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0122\n",
            "Epoch 15/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0115 \n",
            "Epoch 16/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0106 \n",
            "Epoch 17/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0101  \n",
            "Epoch 18/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0099 \n",
            "Epoch 19/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0095\n",
            "Epoch 20/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0092 \n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0063\n",
            "Reconstruction error: 0.006388770882040262\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "# Build and train ARIMA model for forecasting\n",
        "arima_model = ARIMA(data['soil_moisture'], order=(5,1,0))  # ARIMA(5,1,0)\n",
        "arima_model_fit = arima_model.fit()\n",
        "\n",
        "# Make ARIMA predictions\n",
        "arima_forecast = arima_model_fit.forecast(steps=10)\n",
        "print(f\"ARIMA Forecast: {arima_forecast}\")\n",
        "\n",
        "# Build and train LSTM model for forecasting\n",
        "X_lstm = data['soil_moisture'].values.reshape(-1, 1)\n",
        "X_lstm = X_lstm.astype('float32')\n",
        "X_lstm = MinMaxScaler(feature_range=(0, 1)).fit_transform(X_lstm)\n",
        "\n",
        "# Prepare the data for LSTM input\n",
        "X_lstm_data, y_lstm_data = [], []\n",
        "for i in range(60, len(X_lstm)):\n",
        "    X_lstm_data.append(X_lstm[i-60:i, 0])\n",
        "    y_lstm_data.append(X_lstm[i, 0])\n",
        "X_lstm_data = np.array(X_lstm_data) #Rename to avoid conflict\n",
        "y_lstm_data = np.array(y_lstm_data)\n",
        "\n",
        "# Check if X_lstm_data is empty and handle accordingly\n",
        "if X_lstm_data.size == 0:\n",
        "    print(\"Error: Not enough data points to create LSTM input.\")\n",
        "else:\n",
        "    # Build LSTM model\n",
        "    lstm_model = Sequential()\n",
        "    lstm_model.add(LSTM(units=50, return_sequences=True, input_shape=(X_lstm_data.shape[1], 1)))\n",
        "    lstm_model.add(LSTM(units=50, return_sequences=False))\n",
        "    lstm_model.add(Dense(units=1))\n",
        "\n",
        "    lstm_model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "    lstm_model.fit(X_lstm_data, y_lstm_data, epochs=10, batch_size=32)\n",
        "\n",
        "    # Predict with LSTM\n",
        "    lstm_forecast = lstm_model.predict(X_lstm_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "veIsoOYsrgg9",
        "outputId": "df4a8d4c-d902-4fc4-fc27-44b07fd9862a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ARIMA Forecast: 1000    50.677487\n",
            "1001    53.818498\n",
            "1002    55.653345\n",
            "1003    52.349393\n",
            "1004    52.204757\n",
            "1005    53.357082\n",
            "1006    52.835371\n",
            "1007    53.494425\n",
            "1008    53.380469\n",
            "1009    52.881299\n",
            "Name: predicted_mean, dtype: float64\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 56ms/step - loss: 0.1026\n",
            "Epoch 2/10\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - loss: 0.0187\n",
            "Epoch 3/10\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - loss: 0.0208\n",
            "Epoch 4/10\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 62ms/step - loss: 0.0198\n",
            "Epoch 5/10\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - loss: 0.0188\n",
            "Epoch 6/10\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - loss: 0.0211\n",
            "Epoch 7/10\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 59ms/step - loss: 0.0203\n",
            "Epoch 8/10\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - loss: 0.0210\n",
            "Epoch 9/10\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - loss: 0.0195\n",
            "Epoch 10/10\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - loss: 0.0202\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a6sGsTfmsmtk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}